mean1 <- c(1, 1, 1)
sd1 <- c(1, 2, 1)
mean2 <- c(10, -3, 5)
sd2 <- c(2, 1, 2)
mean3 <- c(-5, -5, -5)
sd3 <- c(1.5, 2, 1)
clust1 <- rnorm.multidim(100, mean1, sd1)
clust2 <- rnorm.multidim(100, mean2, sd2)
clust3 <- rnorm.multidim(100, mean3, sd3)
toydata <- rbind(clust1,rbind(clust2,clust3))
rnorm.multidim <- function(n,mean,sd,colstr='x'){
ndim <- length(mean)
data <- NULL
for (i in 1:ndim){
col <- rnorm(n,mean=mean[i],sd=sd[i])
data <- cbind(data,col)
}
cnames <- paste(colstr,1:ndim,sep='')
colnames(data) <- cnames
data
}
mean1 <- c(1, 1, 1)
sd1 <- c(1, 2, 1)
mean2 <- c(10, -3, 5)
sd2 <- c(2, 1, 2)
mean3 <- c(-5, -5, -5)
sd3 <- c(1.5, 2, 1)
clust1 <- rnorm.multidim(100, mean1, sd1)
clust2 <- rnorm.multidim(100, mean2, sd2)
clust3 <- rnorm.multidim(100, mean3, sd3)
toydata <- rbind(clust1,rbind(clust2,clust3))
tmatrix <- scale(toydata)
tcenter <- attr(tmatrix,'scaled:center')
tscale <- attr(tmatrix,'scaled:scale')
kbest.t <- 3
tclusters <- kmeans(tmatrix, kbest.t, nstart=100, iter.max=100)
summary(tclusters)
tclusters$size
unscale(tclusters$centers[1,],tcenter,tscale)
unscale <- function(x,mean,sd){
x*sd+mean
}
unscale(tclusters$centers[1,],tcenter,tscale)
unscale(tclusters$centers[1,],tcenter,tscale)
tclusters$centers[1,]
tcenter
tscale
unscale(tclusters$centers[2,], tcenter, tscale)
tclusters$centers[2,]
unscale(tclusters$centers[3,], tcenter, tscale)
assign_cluster(rnorm.multidim(1, mean1, sd1), tclusters$centers, tcenter, tscale)
assign_clusters(rnorm.multidim(1, mean1, sd1), tclusters$centers, tcenter, tscale)
assign_clusters(rnorm.multidim(1, mean2, sd2), tclusters$centers, tcenter, tscale)
assign_clusters(rnorm.multidim(1, mean3, sd3), tclusters$centers, tcenter, tscale)
library(arules)
library(ggplot2)
library(arules)
library(ggplot2)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",
cols=c("userid", "title"),
rm.duplicates=T)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",
rm.duplicates=T)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",ccols = NULL
rm.duplicates=T)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",cols = NULL
rm.duplicates=T)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",cols = NULL,
rm.duplicates=T)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",cols=c("userid", "title"),
rm.duplicates=T)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",cols=c("userid", "title"),
rm.duplicates=T, header = T)
summary(bookbaskets)
class(bookbaskets)
[1] "transactions"
attr(,"package")
[1] "arules"
> bookbasketssedew
d
library(arules)
library(ggplot2)
bookbaskets <- read.transactions("bookdata.tsv.gz", format="single",
sep="\t",cols=c("userid", "title"),rm.duplicates=T, header = T)
summary(bookbaskets)
class(bookbaskets)
bookbaskets
dim(bookbaskets)
colnames(bookbaskets)
colnames(bookbaskets)[1:10]
rownames(bookbaskets)[1:10]
source('~/R/Data-science-fundamentals/Association_Rules.R')
colnames(bookbaskets)[1:10]
rownames(bookbaskets)[1:10]
bookbaskets[1]
size(bookbasket)[1]
size(bookbaskets)[1]
inspect(bookbaskets[1])
inspect(bookbaskets[1:10])
inspect(bookbaskets[1:3])
size(bookbaskets)[2]
size(bookbaskets[1])
size(bookbaskets[2])
size(bookbaskets[1:5])
inspect(bookbaskets[5])
booksize <- size(bookbaskets)
summary(booksize)
quantile(booksize,c(0.1))
quantile(booksize,c(0.1,1,0.1))
quantile(booksize,c(0,1,0.1))
quantile(booksize,seq(c(0,1,0.1)))
quantile(booksize,seq((0,1,0.1)))
quantile(booksize,seq(0,1,0.1))
quantile(booksize,probs=seq(0,1,0.1))
ggplot(data.frame(count=booksize),aes(x=count))+
geom_density()
ggplot(data.frame(count=booksize),aes(x=count))+
geom_density()+
scale_x_log10()
ggplot(data.frame(count=booksize),aes(x=count))+
geom_density(aes(binwidth=1))+
scale_x_log10()
itemFrequency(bookbaskets)
bookfrq <- itemFrequency(bookbaskets)
bookfreq <- itemFrequency(bookbaskets)
summary(bookfreq)
sum(bookfreq)
sum(booksize)
booksize <- size(bookbaskets)
summary(booksize)
b=booksize/sum(booksize)
booksize/sum(booksize)
summary(booksize/sum(booksize))
summary(bookfreq)
summary((booksize/sum(booksize))*sum(bookfreq))
(bookfreq)[1]
b=summary((booksize/sum(booksize))*sum(bookfreq))
b[1]
inspect(b[1])
summary((bookfreq/sum(booksize))*sum(bookfreq))
bookcount=summary((bookfreq/sum(bookfreq))*sum(booksize))
summary(bookcount)
summary(bookcount)
bookcount[1]
bookcount=(bookfreq/sum(bookfreq))*sum(booksize)
summary(bookcount)
bookcount[1]
inspect(bookcount[1])
inspect(bookcount)
summary(bookfreq)[1]
(bookfreq)[1]
?itemFrequency
summary(bookfreq)
sum(bookfreq)
sum(booksize)
summary(booksize)
summary(bookcount)
itemFrequency(bookbaskets)[1]
itemFrequency(bookbaskets[1])
(bookbaskets[1])
itemFrequency(bookbaskets[1:2])
bookbaskets[1]
inspect(bookbaskets[1])
itemFrequency(bookbaskets)[1]
(bookfreq)[1]
summary(bookfreq)
m=sum(bookbasket,MARGIN=2)
m=sum(bookbaskets,MARGIN=2)
m=sum(matrix(bookbaskets),MARGIN=2)
matrix(bookbaskets)
as.matrix(bookbaskets)
summary(bookcount)
summary((bookfreq)*sum(booksize))
summary((bookfreq*sum(booksize))/(sum(bookfreq)))
summary((bookfreq*sum(booksize)/(sum(bookfreq)))
summary((bookfreq*sum(booksize)/(sum(bookfreq))
summary(bookfreq*sum(booksize)/sum(bookfreq))
length(bookfreq)
bookbaskets
length(booksize)
length(bookcount)
orderedBooks <- sort(bookCount, decreasing=T)
orderedBooks <- sort(bookcount, decreasing=T)
orderedBooks[1:10]
bookcount[1]
orderedBooks[1]/dim(bookbaskets)[1]
summary(bookfreq)
sum(booksize)/sum(bookfreq)
# sum(booksize)/sum(bookfreq) = dim(bookbaskets)[2]
bookcount=bookfreq * dim(bookbaskets)[2]
summary(bookcount)
sum(booksize)/sum(bookfreq)
dim(bookbaskets)[2]
# sum(booksize)/sum(bookfreq) = dim(bookbaskets)[2]
bookcount=bookfreq * dim(bookbaskets)[1]
summary(bookcount)
bookcount[1]
sum(bookbaskets)
sum(bookbaskets[1])
bookbaskets_use <- bookbaskets[bookbaskets>1]
bookbaskets_use <- bookbaskets[booksize>1]
dim(bookbaskets_use)
rules <- apriori(bookbaskets_use,
parameter =list(support = 0.002, confidence=0.75))
summary(rules)
rule[1]
rules[1]
inspect(rules)[1]
inspect(rules[1])
# Coverage is the support of the left side of the rule (X)
# Fisher’s exact test is a significance test for whether an observed pattern is real
#          or chance (the same thing lift measures; Fisher’s test is more formal).
measures <- interestMeasure(rules,methods=c('coverage','fishersExactTest'),transactions = bookbaskets_use)
# Coverage is the support of the left side of the rule (X)
# Fisher’s exact test is a significance test for whether an observed pattern is real
#          or chance (the same thing lift measures; Fisher’s test is more formal).
measures <- interestMeasure(rules,methods=c('coverage','fishersExactTest'),transactions = bookbaskets_use)
summary(measures)
# Coverage is the support of the left side of the rule (X)
# Fisher’s exact test is a significance test for whether an observed pattern is real
#          or chance (the same thing lift measures; Fisher’s test is more formal).
measures <- interestMeasure(rules,method=c('coverage','fishersExactTest'),transactions = bookbaskets_use)
summary(measures)
measures <- interestMeasure(rules, method=c("coverage", "fishersExactTest"),
transactions=bookbaskets_use)
summary(measures)
inspect(head(sort(rules,by='confidence')),n=5)
brules <- apriori(bookbaskets_use,parameter =list((support = 0.002, confidence=0.75)),
brules <- apriori(bookbaskets_use,parameter =list((support = 0.002, confidence=0.75)),
appearance=list(rhs=c("The Lovely Bones: A Novel"),default='lhs'))
brules <- apriori(bookbaskets_use,parameter =list(support = 0.002, confidence=0.75),
appearance=list(rhs=c("The Lovely Bones: A Novel"),default='lhs'))
summary(brules)
brules <- apriori(bookbaskets_use,parameter =list(support = 0.001, confidence=0.6),
appearance=list(rhs=c("The Lovely Bones: A Novel"),default='lhs'))
summary(brules)
inspect(head(sort(brules,by='confidence')),n=5)
brulesSub <- subset(brules, subset=!(lhs %in% "Lucky : A Memoir"))
brulesConf <- sort(brulesSub, by="confidence")
inspect(head(lhs(brulesConf), n=5))
library(randomForest)
spamD <- read.table('spamD.tsv',header=T)
spamD <- read.table('spamD.txt',sep='\t',header=T)
str(spamD)
spam_train <- spamD[spamD$rgroup>=10]
spam_train <- spamD[spamD$rgroup>=10,]
spam_test <- spamD[spamD$rgroup<10]
spam_test <- spamD[spamD$rgroup<10,]
spamvars <- setdiff(colnames(spamD),c('rgroup','spam'))
fml <- paste('spam',paste(spamvars,sep='+'),sep='~')
fml
fml <- paste('spam=="spam"',paste(spamvars,collapse='+'),sep='~')
fml
loglikelihood <- function(y,py){
pysmooth <- ifelse(py==0,1e-12,ifelse(py==1,1e-12,py))
sum(y*log(pysmooth)+(1-y)*og(1-pysmooth))
}
library(rpart)
model <- rpart(fml,spam_train)
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure <- function(pred,truth,name='model'){
dev.normalize <- -2*loglikelihood(as.numeric(truth),pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
spam_train$spam
as.numeric(spam_train$spam)
loglikelihood <- function(y,py){
pysmooth <- ifelse(py==0,1e-12,ifelse(py==1,1e-12,py))
sum(y*log(pysmooth)+(1-y)*log(1-pysmooth))
}
accuracy_measure <- function(pred,truth,name='model'){
dev.normalize <- -2*loglikelihood(as.numeric(truth),pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
model <- rpart(fml,spam_train)
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure <- function(pred,truth,name='model'){
dev.normalized <- -2*loglikelihood(as.numeric(truth),pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure(precict(model,spam_test),spam_test$spam,name='test_model')
accuracy_measure(predict(model,spam_test),spam_test$spam,name='test_model')
loglikelihood <- function(y,py){
pysmooth <- ifelse(py==0,1e-12,ifelse(py==1,1e-12,py))
sum(y*log(pysmooth)+((1-y)*log(1-pysmooth)))
}
accuracy_measure <- function(pred,truth,name='model'){
dev.normalized <- -2*loglikelihood(as.numeric(truth),pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure(predict(model,spam_test),spam_test$spam,name='test_model')
fml <- paste('spam',paste(spamvars,collapse='+'),sep='~')
model <- rpart(fml,spam_train)
predict(model,spam_train)
fml <- paste('spam=="spam"',paste(spamvars,collapse='+'),sep='~')
model <- rpart(fml,spam_train)
predict(model,spam_train)
# Random Forest
n_train <- dim(spam_train)[1]
n <- n_train
n_tree <- 100
samples <- sapply(1:n_tree, FUN=function(iter){
sample(1:n_train,size = n,replace = T)
})
samples
n
str(samples)
dim(samples)
tree_list <- lapply(1:n_tree,FUN=function(iter){
samp <- samples[,iter]
rpart(fml,spam_train[samp,])
})
dim(tree_list)
tree_list
tree_list[1]
dim(tree_list)
length(tree_list)
predict.bag <- function(treelist,newdata){
preds <- sapply(1:length(treelist), FUN=function(iter){
predict(treelist[iter],newdata)
})
predsums <- rowSums(preds)
predsums/length(treelist)
}
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam,name='bagging_training')
tree_list[1]
tree_list[[1]]
predict.bag <- function(treelist,newdata){
preds <- sapply(1:length(treelist), FUN=function(iter){
predict(treelist[[iter]],newdata)
})
predsums <- rowSums(preds)
predsums/length(treelist)
}
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam,name='bagging_training')
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure(predict(model,spam_test),spam_test$spam,name='test_model')
tree_list <- lapply(1:n_tree,FUN=function(iter){
samp <- samples[,iter]
rpart(fml,spam_train[samp,])
})
length(tree_list)
tree_list[[1]]
predict.bag <- function(treelist,newdata){
preds <- sapply(1:length(treelist), FUN=function(iter){
predict(treelist[[iter]],newdata)
})
predsums <- rowSums(preds)
predsums/length(treelist)
}
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam,name='bagging_training')
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure(predict(model,spam_test),spam_test$spam,name='test_model')
accuracy_measure(predict.bag(tree_list,spam_train),spam_train$spam,name='bagging_training')
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam,name='bagging_testing')
# Random Forest
set.seed(123)
rmodel <- randomForest(fml,spam_train,ntree = 100,nodesize = 7,importance=T)
rmodel <- randomForest(spam_train[,spamvars],spam_train$spam,ntree = 100,nodesize = 7,importance=T)
predict(rmodel,spam_train)
predict(rmodel,spam_train,type='prob')
rmodel <- randomForest(fml,spam_train,ntree = 100,nodesize = 7,importance=T)
rmodel <- randomForest(fml,spam_test,ntree = 100,nodesize = 7,importance=T)
predict(rmodel,spam_train,type='prob')['spam']
predict(rmodel,spam_train,type='prob')[,'spam']
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam,name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam,name='randomForest_training')
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure(predict(model,spam_test),spam_test$spam,name='test_model')
accuracy_measure(predict.bag(tree_list,spam_train),spam_train$spam,name='bagging_training')
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam,name='bagging_testing')
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam,name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam,name='randomForest_training')
str(spamD)
summary(rmodel)
rmodel
str(rmodel)
rmodel
summary(
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam,name='randomForest_training')
summary(rmodel)
summary(rmodel)
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam,name='randomForest_training')
predict(rmodel,spam_test,type='prob')[,'spam']
loglikelihood(spam_train$spam,predict(rmodel,spam_train,type='prob')[,'spam'])
loglikelihood(as.numeric(spam_train$spam),predict(rmodel,spam_train,type='prob')[,'spam'])
-2*loglikelihood(as.numeric(spam_train$spam),predict(rmodel,spam_train,type='prob')[,'spam'])
-2*loglikelihood(as.numeric(spam_train$spam),predict(rmodel,spam_train,type='prob')[,'spam'])/length(spam_train$spam)
-2*loglikelihood(as.numeric(spam_train$spam),predict(model,spam_train,type='prob')[,'spam'])/length(spam_train$spam)
-2*loglikelihood(as.numeric(spam_train$spam),predict(model,spam_train)/length(spam_train$spam)
-2*loglikelihood(as.numeric(spam_train$spam),predict(model,spam_train))/length(spam_train$spam)
-2*loglikelihood(as.numeric(spam_train$spam),predict(model,spam_train))/length(spam_train$spam)
-2*loglikelihood(as.numeric(spam_train$spam),predict(model,spam_train))
str(spamD)
as.factor(spam_train$spam)
values(spam_train$spam)
lavels(spam_train$spam)
levels(spam_train$spam)
levels(spam_train$spam)=c(0,1)
as.factor(spam_train$spam)
str(spamD)
str(spam_train)
spam_train <- spamD[spamD$rgroup>=10,]
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam,name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam,name='randomForest_training')
summary(rmodel)
rmodel$ntree
rmodel$err.rate
accuracy_measure <- function(pred,truth,name='model'){
tr=ifelse(truth=='spam',1,0)
dev.normalized <- -2*loglikelihood(as.numeric(truth),pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam,name='randomForest_training')
accuracy_measure <- function(pred,truth,name='model'){
tr=ifelse(truth=='spam',1,0)
dev.normalized <- -2*loglikelihood(tr,pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam,name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam,name='randomForest_training')
accuracy_measure(predict.bag(tree_list,spam_train),spam_train$spam,name='bagging_training')
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam,name='bagging_testing')
accuracy_measure <- function(pred,truth,name='model'){
tr=ifelse(truth=='spam',1,ifelse(trurh=='non-spam',0,as.numeric(truth)))
dev.normalized <- -2*loglikelihood(tr,pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam=='spam',name='randomForest_training')
spam_train$spam=='spam'
accuracy_measure <- function(pred,truth,name='model'){
tr=ifelse(truth=='spam',1,ifelse(truth=='non-spam',0,as.numeric(truth)))
dev.normalized <- -2*loglikelihood(tr,pred)/length(pred)
ctable <- table(truth=truth,pred=(pred>0.5))
accuracy <- sum(diag(ctable))/(sum(ctable))
prec <- ctable[2,2]/(ctable[2,2]+ctable[1,2])
recall=ctable[2,2]/(ctable[2,2]+ctable[2,1])
f1 <- 2*prec*recall/(prec+recall)
data.frame(model=name,accuracy=accuracy,deviance=dev.normalized,precision=prec,recall=recall,f1_score=f1)
}
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam=='spam',name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam=='non-spam',name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam=='spam',name='randomForest_training')
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam=='spam',name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam=='spam',name='randomForest_training')
accuracy_measure(predict(rmodel,spam_test,type='prob')[,'spam'],spam_test$spam=='spam',name='randomForest_testing')
accuracy_measure(predict.bag(tree_list,spam_train),spam_train$spam=='spam',name='bagging_training')
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam=='spam',name='bagging_testing')
accuracy_measure(predict(model,spam_train),spam_train$spam,name='training_model')
accuracy_measure(predict.bag(tree_list,spam_train),spam_train$spam,name='bagging_training')
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam',name='bagging_testing')
accuracy_measure(predict.bag(tree_list,spam_test),spam_test$spam,name='bagging_testing')
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam=='spam',name='randomForest_training')
varimp=importance(rmodel)
varimp[1:10]
varimp[1:10,]
dim(varimp)
varImpPlot(rmodel)
varImpPlot(rmodel,type=1)
selvar=names(sort(varimp[,1],decreasing = T))[1:25]
selvar
new_rmodel <- randomForest(spam_train[,selvar],spam_train$spam,ntree = 100,nodesize = 7,importance=T)
accuracy_measure(predict(new_rmodel,spam_train,type='prob')[,'spam'],spam_train$spam=='spam',name='randomForest_training')
accuracy_measure(predict(rmodel,spam_train,type='prob')[,'spam'],spam_train$spam=='spam',name='randomForest_training')
accuracy_measure(predict(new_rmodel,spam_test,type='prob')[,'spam'],spam_test$spam=='spam',name='randomForest_testing')
accuracy_measure(predict(new_rmodel,spam_train,type='prob')[,'spam'],spam_train$spam=='spam',name='New_randomForest_training')
accuracy_measure(predict(new_rmodel,spam_test,type='prob')[,'spam'],spam_test$spam=='spam',name='New_randomForest_testing')
